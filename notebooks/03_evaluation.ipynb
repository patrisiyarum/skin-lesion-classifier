{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 â€” Evaluation\n",
        "\n",
        "Full evaluation of the trained model on the test set:\n",
        "- Classification report (precision, recall, F1)\n",
        "- Confusion matrix\n",
        "- ROC curves and AUC\n",
        "- Per-class sensitivity & specificity\n",
        "- Grad-CAM visual explanations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os\n",
        "sys.path.insert(0, os.path.abspath('..'))\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from src.config import CONFIG, CLASS_NAMES, MODELS_DIR, IDX_TO_LABEL, get_device\n",
        "from src.utils.seed import set_seed\n",
        "from src.data.dataset import get_dataloaders\n",
        "from src.models.model import build_model, get_grad_cam\n",
        "from src.models.loss import get_criterion\n",
        "from src.train.evaluate import evaluate\n",
        "from src.utils.metrics import compute_metrics, compute_binary_auc, sensitivity_specificity, get_classification_report\n",
        "from src.utils.visualization import plot_confusion_matrix, plot_roc_curve_binary, plot_grad_cam\n",
        "from src.data.transforms import denormalize\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "DEVICE = get_device()\n",
        "set_seed(CONFIG['seed'])\n",
        "print(f'Device: {DEVICE}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = build_model(pretrained=False)\n",
        "ckpt = torch.load(MODELS_DIR / 'best_model.pth', map_location=DEVICE)\n",
        "model.load_state_dict(ckpt['model_state_dict'])\n",
        "model = model.to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "print(f\"Loaded checkpoint from epoch {ckpt.get('epoch', '?')} with val_acc={ckpt.get('val_acc', '?')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Run evaluation on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaders = get_dataloaders()\n",
        "test_loader = loaders['test']\n",
        "\n",
        "criterion = get_criterion(device=DEVICE)\n",
        "loss, acc, preds, labels, probs = evaluate(model, test_loader, criterion, DEVICE)\n",
        "\n",
        "print(f'Test Loss:     {loss:.4f}')\n",
        "print(f'Test Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = compute_metrics(labels, preds)\n",
        "print('Aggregate metrics:', metrics)\n",
        "print()\n",
        "print(get_classification_report(labels, preds, class_names=CLASS_NAMES))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_confusion_matrix(labels, preds, class_names=CLASS_NAMES)\n",
        "print()\n",
        "plot_confusion_matrix(labels, preds, class_names=CLASS_NAMES, normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. ROC curves & AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "auc_score = compute_binary_auc(labels, probs)\n",
        "print(f'Binary AUC: {auc_score:.4f}')\n",
        "\n",
        "plot_roc_curve_binary(labels, probs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Per-class sensitivity & specificity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ss = sensitivity_specificity(labels, preds)\n",
        "\n",
        "import pandas as pd\n",
        "ss_df = pd.DataFrame({\n",
        "    'class': CLASS_NAMES,\n",
        "    'sensitivity': [f'{v:.4f}' for v in ss['sensitivity']],\n",
        "    'specificity': [f'{v:.4f}' for v in ss['specificity']],\n",
        "})\n",
        "ss_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Grad-CAM visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cam = get_grad_cam(model)\n",
        "\n",
        "# Grab a few test images\n",
        "test_iter = iter(test_loader)\n",
        "images, true_labels = next(test_iter)\n",
        "\n",
        "for i in range(min(5, len(images))):\n",
        "    img_tensor = images[i].unsqueeze(0).to(DEVICE)\n",
        "    heatmap = cam(img_tensor)\n",
        "    orig_np = denormalize(img_tensor)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logit = model(img_tensor).squeeze()\n",
        "        prob_mal = torch.sigmoid(logit).item()\n",
        "        pred_idx = int(prob_mal >= 0.5)\n",
        "\n",
        "    true_name = IDX_TO_LABEL[true_labels[i].item()]\n",
        "    pred_name = IDX_TO_LABEL[pred_idx]\n",
        "    confidence = prob_mal if pred_idx == 1 else 1.0 - prob_mal\n",
        "    plot_grad_cam(\n",
        "        orig_np, heatmap,\n",
        "        predicted_label=pred_name,\n",
        "        true_label=true_name,\n",
        "        confidence=confidence,\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
