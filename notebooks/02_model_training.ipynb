{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 — Model Training\n",
        "\n",
        "Interactive training notebook:\n",
        "- Build dataloaders\n",
        "- Configure and build the model\n",
        "- Run training with live loss/accuracy tracking\n",
        "- Plot training curves\n",
        "- Save the best checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os\n",
        "sys.path.insert(0, os.path.abspath('..'))\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from src.config import CONFIG, get_device\n",
        "from src.utils.seed import set_seed\n",
        "from src.data.dataset import get_dataloaders, SkinLesionDataset\n",
        "from src.models.model import build_model\n",
        "from src.models.loss import get_criterion\n",
        "from src.train.train import train_one_epoch, get_optimizer, get_scheduler\n",
        "from src.train.evaluate import evaluate\n",
        "from src.utils.metrics import compute_binary_auc\n",
        "from src.utils.visualization import plot_training_curves\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "DEVICE = get_device()\n",
        "print(f'Device: {DEVICE}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration overrides\n",
        "\n",
        "Adjust hyperparameters here before training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Override any CONFIG values for this run\n",
        "CONFIG['epochs'] = 30\n",
        "CONFIG['learning_rate'] = 1e-4\n",
        "CONFIG['batch_size'] = 32\n",
        "CONFIG['model_name'] = 'efficientnet_b0'\n",
        "CONFIG['loss'] = 'bce'             # binary classification → BCEWithLogitsLoss\n",
        "CONFIG['scheduler'] = 'cosine'\n",
        "\n",
        "set_seed(CONFIG['seed'])\n",
        "print('Config:', CONFIG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaders = get_dataloaders()\n",
        "\n",
        "for name, loader in loaders.items():\n",
        "    if loader is not None:\n",
        "        print(f'{name:>5}: {len(loader.dataset)} samples, {len(loader)} batches')\n",
        "    else:\n",
        "        print(f'{name:>5}: None')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Peek at a batch\n",
        "images, labels = next(iter(loaders['train']))\n",
        "print(f'Batch shape: {images.shape}, Labels: {labels[:8]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Build model, loss, optimiser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = build_model().to(DEVICE)\n",
        "\n",
        "# Compute pos_weight for imbalanced binary data\n",
        "train_ds: SkinLesionDataset = loaders['train'].dataset\n",
        "pos_weight = train_ds.compute_pos_weight()\n",
        "print('pos_weight (neg/pos):', pos_weight.item())\n",
        "\n",
        "criterion = get_criterion(pos_weight=pos_weight, device=DEVICE)\n",
        "optimizer = get_optimizer(model)\n",
        "scheduler = get_scheduler(optimizer)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Parameters: {total_params:,} total, {trainable:,} trainable')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.config import MODELS_DIR\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "history = {\n",
        "    'train_loss': [], 'train_acc': [], 'train_auc': [],\n",
        "    'val_loss': [], 'val_acc': [], 'val_auc': [],\n",
        "}\n",
        "best_val_auc = 0.0\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(CONFIG['epochs']):\n",
        "    lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"\\nEpoch {epoch+1}/{CONFIG['epochs']}  lr={lr:.2e}\")\n",
        "\n",
        "    # Train\n",
        "    train_metrics = train_one_epoch(\n",
        "        model, loaders['train'], criterion, optimizer, DEVICE,\n",
        "        grad_clip=CONFIG.get('grad_clip_max_norm'),\n",
        "    )\n",
        "\n",
        "    # Validate\n",
        "    val_loss, val_acc, val_preds, val_labels, val_probs = evaluate(\n",
        "        model, loaders['val'], criterion, DEVICE,\n",
        "    )\n",
        "    val_auc = compute_binary_auc(val_labels, val_probs)\n",
        "\n",
        "    # Scheduler\n",
        "    if scheduler is not None:\n",
        "        if isinstance(scheduler, ReduceLROnPlateau):\n",
        "            scheduler.step(val_loss)\n",
        "        else:\n",
        "            scheduler.step()\n",
        "\n",
        "    print(f\"  train  loss={train_metrics['loss']:.4f}  acc={train_metrics['acc']:.4f}  auc={train_metrics['auc']:.4f}\")\n",
        "    print(f\"  val    loss={val_loss:.4f}  acc={val_acc:.4f}  auc={val_auc:.4f}\")\n",
        "\n",
        "    history['train_loss'].append(train_metrics['loss'])\n",
        "    history['train_acc'].append(train_metrics['acc'])\n",
        "    history['train_auc'].append(train_metrics['auc'])\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_auc'].append(val_auc)\n",
        "\n",
        "    # Save best model by validation AUC (consistent with train.py)\n",
        "    if val_auc > best_val_auc:\n",
        "        best_val_auc = val_auc\n",
        "        patience_counter = 0\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_auc': best_val_auc,\n",
        "            'val_acc': val_acc,\n",
        "            'val_loss': val_loss,\n",
        "            'config': CONFIG,\n",
        "        }, MODELS_DIR / 'best_model.pth')\n",
        "        print(f'  -> saved best model (val_auc={best_val_auc:.4f})')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= CONFIG['early_stopping_patience']:\n",
        "        print(f'\\nEarly stopping at epoch {epoch+1}')\n",
        "        break\n",
        "\n",
        "print(f'\\nDone. Best val AUC = {best_val_auc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_training_curves(history)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
